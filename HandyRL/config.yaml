env_args:
    env: 'handyrl.envs.Halite'
    #env: 'Geister'
    #env: 'HungryGeese'
    #env: 'handyrl.envs.parallel_tictactoe'  # specify by path

train_args:
    turn_based_training: False
    observation: False
    gamma: 0.999
    lambda: 0.98
    forward_steps: 32
    burn_in_steps: 0  # for RNNs
    compress_steps: 4
    entropy_regularization: 2.0e-3
    entropy_regularization_decay: 0.3
    update_episodes: 500
    batch_size: 64
    minimum_episodes: 10000
    maximum_episodes: 2000000
    epochs: -1
    num_batchers: 12
    eval_rate: 0.1
    worker:
        num_parallel: 32
        
    policy_target: 'UPGO' # 'UPGO' 'VTRACE' 'TD' 'MC'
    value_target: 'TD' # 'VTRACE' 'TD' 'MC'
    
    eval:
        opponent: ['random']
    seed: 0
    restart_epoch: 0


worker_args:
    server_address: ''
    num_parallel: 8
